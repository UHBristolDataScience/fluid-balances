{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook we process data extracted from the Philipis ICCA system in Bristol, UK for use in an audit and machine learning project with CORMSIS, Southampton.  \n",
    "\n",
    "### Data are processed to faciliate rapid analysis by CORMSIS student KQ. De-identification follows standards required by CAG guidelines for clinical audit involving a third party.\n",
    "\n",
    "Note: The following bash commands respectively remove trailing and preceding lines from the report files. (This is required for clean loading with pandas.read_csv).\n",
    "* sed -i '$ d' ptassess_physiological_data.rpt\n",
    "* sed -i '1d' ptassess_physiological_data.rpt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. First we produce the (patient) summary data for all ICU stays in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stays = pd.read_csv('patient_stays_summary.rpt', delimiter='\\t')\n",
    "demographics = pd.read_csv('patient_demographics_heights_weights.rpt', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "demographics.groupby('interventionId').agg({'longLabel':['count', 'first']}); ## output supressed for data protection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple interventionId numbers in use. We expect there to be duplication. For example, \"Weight (Admission)\" and \"Weight (admission)\" are frequently both entered for the same encounter. Not clear why.\n",
    "\n",
    "####  We define an order of priority and select one weight and one height for each ICU stay as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_priority = [4615, 2110, 8917, 10098, 2079, 8906, 4853]\n",
    "height_priority = [2714, 2377]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = dict()\n",
    "heights = dict()\n",
    "\n",
    "for ii in demographics['encounterId'].unique():\n",
    "    \n",
    "    subset = demographics[demographics['encounterId']==ii]\n",
    "    weight = (np.nan, np.nan)\n",
    "    height = (np.nan, np.nan)\n",
    "    \n",
    "    for wid in weight_priority:\n",
    "        w = subset[subset['interventionId']==wid]\n",
    "        if len(w)>0:\n",
    "            weight = (w['chartTime'].values[0], w['valueNumber'].values[0])\n",
    "            break\n",
    "            \n",
    "    for hid in height_priority:\n",
    "        h = subset[subset['interventionId']==hid]\n",
    "        if len(h)>0:\n",
    "            height = (h['chartTime'].values[0], h['valueNumber'].values[0])\n",
    "            break\n",
    "            \n",
    "    weights[ii] = weight\n",
    "    heights[ii] = height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We now convert the inTime column to type datetime, and then remove MOST sensitive data (inTime will be removed later after being used to convert other time stamps in the data). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##print stays.dtypes\n",
    "stays['inTime'] = pd.to_datetime(stays['inTIME'], infer_datetime_format=True)\n",
    "anon = stays.drop(labels=['tNumber', 'numberOfRecords', 'inTIME', 'outTime'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add in weights and heights as calculated above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anon['weight'] = anon.encounterId.apply(lambda x: weights[x][1] if x in weights.keys() else np.nan)\n",
    "anon['height'] = anon.encounterId.apply(lambda x: heights[x][1] if x in heights.keys() else np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Josh Inoue (from Univeristy Hospitals Bristol) has compiled a list of bad encounterId numbers. These are ICU stays which were created in error or involve some other type of data corruption. We load the lists of these ID numbers and then remove them from our  summary data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "erroneous_entries = pd.read_excel('../../working with ICNARC/Philips encounterId Issue List (New).xlsx', sheet_name='encounterId')\n",
    "erroneous_entries2 = pd.read_excel('../../working with ICNARC/Philips encounterId Issue List (New).xlsx', sheet_name='WW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248 ICU stays to remove.\n"
     ]
    }
   ],
   "source": [
    "err = [e for e in erroneous_entries['encounterId_CIS']]\n",
    "err = err + [e for e in erroneous_entries['encounterId_Adjusted']]\n",
    "err = err + [e for e in erroneous_entries2['Corrected encID']]\n",
    "err = err + [e for e in erroneous_entries2['CIS Patient ID']]\n",
    "to_drop = [i for i,row in anon.iterrows() if row['encounterId'] in err]\n",
    "print \"%d ICU stays to remove.\" %len(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anon = anon.drop(to_drop, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We now further reduce the cohort of patients by selecting only those ICU stays which appear in the ICNARC (national audit) database, or those that were admitted during 2019 (for which we do not currently have the ICNARC data). \n",
    "\n",
    "Linking to ICNARC ensures that we are looking only at genuine stays, not test patients or erroneous entries etc.\n",
    "\n",
    "Note: the patients for which we have ICNARC data we have outcome information (in-hospital mortality), diagnosis and basic medical history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "807 patients not in this extract of the ICANRC data.\n"
     ]
    }
   ],
   "source": [
    "icnarc = pd.read_csv('../../working with ICNARC/ICNARC 2015-2018 encounterIds and Readmissions.TXT')\n",
    "to_drop = [i for i,row in anon.iterrows() if row['encounterId'] not in icnarc['CIS Patient ID'].values]\n",
    "print \"%d patients not in this extract of the ICANRC data.\" %len(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "without_2019 = anon.drop(to_drop, axis=0)\n",
    "only_2019 = anon[anon['inTime']>='2019']\n",
    "anon = without_2019.append(only_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are now 5413 unique ICU stays in the data.\n"
     ]
    }
   ],
   "source": [
    "print \"There are now %d unique ICU stays in the data.\" %len(anon.encounterId.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We now add in the month of admission and day of admission, both as incremental integers beginning from the earliest admission date :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Previously used first inTime, but need to start from midnight ...\n",
    "# DAY_0 = anon['inTime'].iloc[0]\n",
    "DAY_0 = pd.Timestamp(year=2015, month=2, day=1, hour=0, minute=0, second=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anon['admission month'] = anon['inTime'].apply(lambda x : (x.year - 2015) * 12 + x.month)\n",
    "anon['admission day'] = anon['inTime'].apply(lambda x : (x - DAY_0).days)\n",
    "anon['admission time'] = anon['inTime'].apply(lambda x: x.time())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Next we prepare the fluid balance targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targets = pd.read_csv('fluid_balance_target.rpt', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The interventionId 20324 contains gibberish (corrupt data?), therefore we have fewer patients than expected using only 52111:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targets = targets[targets['interventionId']==52111]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We convert chartTime to datetime format and then calculate 'minutes since admission' and 'record day' by joining to the patient summary data (anon). We also get just time of day from 'time': "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targets['time'] = pd.to_datetime(targets['chartTime'], infer_datetime_format=True)\n",
    "targets = targets.merge(anon, on='encounterId')\n",
    "targets['minutes since admission'] = (targets['time'] - targets['inTime']) / pd.Timedelta(minutes=1)\n",
    "targets['record day'] = targets['time'].apply(lambda x:  (x- DAY_0).days)\n",
    "targets['time of day'] = targets['time'].apply(lambda x: x.time())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select only relevant columns and save:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targets = targets[['minutes since admission', 'encounterId', 'valueString', 'record day', 'time of day']]\n",
    "targets.to_csv('anonymised_targets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Then process 'Total balances' (fluids). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "totals = pd.read_csv('total_balances.rpt', delimiter='\\t')\n",
    "totals = totals[['interventionId', 'encounterId', 'chartTime', 'careProviderId', 'hourTotal', 'cumTotal', 'unitOfMeasure', 'longLabel']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We drop any encounterId numbers that do not appear in our patient summary data frame (anon):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_drop = [i for i,row in totals.iterrows() if row['encounterId'] not in anon['encounterId'].values]\n",
    "totals = totals.drop(to_drop, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "totals['time'] = pd.to_datetime(totals['chartTime'], infer_datetime_format=True)\n",
    "totals = totals.merge(anon, on='encounterId')\n",
    "totals['minutes since admission'] = (totals['time'] - totals['inTime']) / pd.Timedelta(minutes=1)\n",
    "totals['record day'] = totals['time'].apply(lambda x:  (x- DAY_0).days)\n",
    "totals['time of day'] = totals['time'].apply(lambda x: x.time())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select relevant columns and save:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5323 ICU stays in this data frame.\n"
     ]
    }
   ],
   "source": [
    "totals = totals[['interventionId', 'encounterId', 'minutes since admission', 'record day', 'time of day' ,'careProviderId', 'hourTotal', 'cumTotal', 'unitOfMeasure', 'longLabel']]\n",
    "totals.to_csv('anonymised_total_balances.csv')\n",
    "print \"There are %d ICU stays in this data frame.\" %len(totals.encounterId.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: there are fewer patients in the fluid balance data frame than in the patient summary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Then process PtLabResult data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labres = pd.read_csv('labresults_physiological_data.rpt', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Same workflow as above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_drop = [i for i,row in labres.iterrows() if row['encounterId'] not in anon['encounterId'].values]\n",
    "labres = labres.drop(to_drop, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labres['time'] = pd.to_datetime(labres['chartTime'], infer_datetime_format=True)\n",
    "labres = labres.merge(anon, on='encounterId')\n",
    "labres['minutes since admission'] = (labres['time'] - labres['inTime']) / pd.Timedelta(minutes=1)\n",
    "labres['record day'] = labres['time'].apply(lambda x:  (x- DAY_0).days)\n",
    "labres['time of day'] = labres['time'].apply(lambda x: x.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5399 ICU stays in this data frame.\n"
     ]
    }
   ],
   "source": [
    "labres = labres[['interventionId', 'encounterId', 'minutes since admission', 'record day', 'time of day' ,'attribute', 'longLabel', 'valueNumber', 'valueString']]\n",
    "labres.to_csv('anonymised_labres.csv')\n",
    "print \"There are %d ICU stays in this data frame.\" %len(labres.encounterId.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Then process PtAssess data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ptassess = pd.read_csv('ptassess_physiological_data.rpt', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_drop = [i for i,row in ptassess.iterrows() if row['encounterId'] not in anon['encounterId'].values]\n",
    "ptassess = ptassess.drop(to_drop, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ptassess['time'] = pd.to_datetime(ptassess['chartTime'], infer_datetime_format=True)\n",
    "ptassess = ptassess.merge(anon, on='encounterId')\n",
    "ptassess['minutes since admission'] = (ptassess['time'] - ptassess['inTime']) / pd.Timedelta(minutes=1)\n",
    "ptassess['record day'] = ptassess['time'].apply(lambda x:  (x- DAY_0).days)\n",
    "ptassess['time of day'] = ptassess['time'].apply(lambda x: x.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5375 ICU stays in this data frame.\n"
     ]
    }
   ],
   "source": [
    "ptassess = ptassess[['interventionId', 'encounterId', 'minutes since admission', 'record day', 'time of day' ,'attribute', 'longLabel', 'valueNumber', 'valueString']]\n",
    "ptassess.to_csv('anonymised_ptassess.csv')\n",
    "print \"There are %d ICU stays in this data frame.\" %len(ptassess.encounterId.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. We now split all the data frames into separate files (one for each ICU stay), to facilitate partial analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ii in anon['encounterId']:\n",
    "    \n",
    "    subset1 = totals[totals['encounterId']==ii]\n",
    "    subset2 = targets[targets['encounterId']==ii]\n",
    "    subset3 = labres[labres['encounterId']==ii]\n",
    "    subset4 = ptassess[ptassess['encounterId']==ii]\n",
    "    \n",
    "    subset1.to_csv('patient_files/total_balances_%d.csv' %ii)\n",
    "    subset2.to_csv('patient_files/targets_%d.csv' %ii)\n",
    "    subset3.to_csv('patient_files/labres_%d.csv' %ii)\n",
    "    subset4.to_csv('patient_files/ptassess_%d.csv' %ii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Having processed all the data we can remove 'inTime' from the patient summary data frame and save it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anon = anon[['encounterId', 'age', 'lengthOfStay (mins)', 'gender', 'weight', 'height', 'admission month', 'admission day', 'admission time']]\n",
    "anon.to_csv('anonymised_patient_summary.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
